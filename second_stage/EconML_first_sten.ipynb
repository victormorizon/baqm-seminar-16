{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, ConfusionMatrixDisplay, average_precision_score, median_absolute_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "import econml.dml as dml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas import get_dummies\n",
    "\n",
    "dml_causal = dml.CausalForestDML\n",
    "\n",
    "df = pd.read_csv(\"../data/prepped_data.csv\", index_col = 0, low_memory= False)\n",
    "df = df[df['first_data_year'] >= 2021]\n",
    "df = df.drop(columns=[ 'last_data_year', 'first_data_year', 'control_group'])\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = []\n",
    "continuous_features = []\n",
    "binary_features = []\n",
    "\n",
    "# Define a threshold for the maximum number of unique values for a categorical column\n",
    "max_unique_values_for_categorical = 10\n",
    "\n",
    "# Iterate through each column to determine if it's categorical, continuous, or binary\n",
    "for column in df.columns:\n",
    "    unique_values = df[column].nunique()\n",
    "    if unique_values == 2:\n",
    "        # If exactly 2 unique values, treat column as binary\n",
    "        binary_features.append(column)\n",
    "    elif (df[column].dtype == 'object' or unique_values <= max_unique_values_for_categorical) and unique_values > 2:\n",
    "        # If object type or up to the threshold of unique values (and more than 2), treat as categorical\n",
    "        categorical_features.append(column)\n",
    "    else:\n",
    "        # Otherwise, treat as continuous\n",
    "        continuous_features.append(column)\n",
    "\n",
    "# categorical_features = [col for col in categorical_features if col != \"years_since_last_car_change\"]\n",
    "# continuous_features = continuous_features + [\"years_since_last_car_change\"]\n",
    "\n",
    "print(f'Binary Features: {binary_features}')\n",
    "print(f'Categorical Features: {categorical_features}')\n",
    "print(f'Continuous Features: {continuous_features}')\n",
    "\n",
    "df = pd.get_dummies(df, columns=categorical_features)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['churn']\n",
    "T = df['welcome_discount']\n",
    "X = df.drop(columns=['churn', 'welcome_discount'])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_first =  {'colsample_bytree': 0.6186073247946325, 'gamma': 0.16809946864097097, 'learning_rate': 0.1201301843520244, 'max_depth': 4.0, 'min_child_weight': 11.0, 'n_estimators': 141.0, 'reg_alpha': 0.9947688530022228, 'reg_lambda': 0.9032451749885752, 'subsample': 0.9954225737300325}\n",
    "\n",
    "model_first = XGBClassifier(\n",
    "    n_estimators=int(best_first['n_estimators']),\n",
    "    max_depth=int(best_first['max_depth']),\n",
    "    learning_rate=best_first['learning_rate'],\n",
    "    subsample=best_first['subsample'],\n",
    "    gamma=best_first['gamma'],\n",
    "    colsample_bytree=best_first['colsample_bytree'],\n",
    "    min_child_weight = best_first['min_child_weight'],\n",
    "    # scale_pos_weight=scale_pos_weight_value,\n",
    "    reg_alpha=best_first['reg_alpha'],\n",
    "    reg_lambda=best_first['reg_lambda'],\n",
    "    objective='binary:logistic',\n",
    "    tree_method='hist',\n",
    "    enable_categorical = True\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "model_first.fit(X_train, y_train)\n",
    "\n",
    "best_second = {'colsample_bytree': 0.8368650515536827, 'gamma': 0.0004689774751606146, 'learning_rate': 0.10657701450178336, 'max_depth': 8.0, 'min_child_weight': 10.0, 'n_estimators': 150.0, 'reg_alpha': 0.3708478046128461, 'reg_lambda': 0.6426896127366873, 'subsample': 0.96392422815337}\n",
    "\n",
    "\n",
    "# Use the best parameters\n",
    "model_second = XGBRegressor(\n",
    "    n_estimators=int(best_second['n_estimators']),\n",
    "    max_depth=int(best_second['max_depth']),\n",
    "    learning_rate=best_second['learning_rate'],\n",
    "    subsample=best_second['subsample'],\n",
    "    gamma=best_second['gamma'],\n",
    "    colsample_bytree=best_second['colsample_bytree'],\n",
    "    min_child_weight = best_second['min_child_weight'],\n",
    "    # scale_pos_weight=scale_pos_weight_value,\n",
    "    reg_alpha=best_second['reg_alpha'],\n",
    "    reg_lambda=best_second['reg_lambda'],\n",
    "    objective='reg:squarederror',\n",
    "    tree_method='hist',\n",
    "    enable_categorical = True\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "model_second.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = dml_causal(model_y=model_first,\n",
    "                     model_t=model_second,\n",
    "                     n_estimators=100,   # Number of trees in the forest\n",
    "                     min_samples_leaf=10,  # Minimum number of samples required to be at a leaf node\n",
    "                     max_depth=None,       # Maximum depth of the tree\n",
    "                     criterion='het',      # Function to measure the quality of a split\n",
    "                    \n",
    "                     # Other parameters can be tuned as required\n",
    "                     )\n",
    "\n",
    "# Fit the model - ensure your features (X) do not have missing values\n",
    "cf.fit(Y=y, T=T, X=X.dropna(axis=1), W=None)\n",
    "\n",
    "# Estimate the causal effect\n",
    "effects = cf.effect(X)\n",
    "\n",
    "effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
