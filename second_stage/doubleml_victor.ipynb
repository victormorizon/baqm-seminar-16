{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import doubleml as dml\n",
    "from doubleml.datasets import make_irm_data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix, roc_auc_score, ConfusionMatrixDisplay, average_precision_score, make_scorer, mean_absolute_error, median_absolute_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/prepped_data.csv\", low_memory=False, index_col=0).drop_duplicates()\n",
    "\n",
    "df = df[df[\"first_data_year\"] >= 2021]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls = [col for col, val in df.isnull().any().to_dict().items() if val == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "welcome_discount          1.0\n",
       "count                       2\n",
       "last_datapoint_year    2023.0\n",
       "first_data_year          2021\n",
       "churn                       1\n",
       "                        ...  \n",
       "last_nr_coverages_1      True\n",
       "last_nr_coverages_2     False\n",
       "last_nr_coverages_3     False\n",
       "last_nr_coverages_4     False\n",
       "last_nr_coverages_5     False\n",
       "Name: 81229, Length: 247, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.loc[81229])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Features: ['count', 'last_datapoint_year', 'first_data_year', 'churn', 'last_allrisk basis', 'last_allrisk compleet', 'last_allrisk royaal', 'last_wa-extra', 'policyholder_change', 'accident_years', 'lpa']\n",
      "Categorical Features: ['policy_nr_hashed', 'last_data_year', 'first_datapoint_year', 'control_group', 'last_brand', 'last_type', 'last_fuel_type', 'last_postcode', 'max_nr_coverages', 'last_nr_coverages']\n",
      "Continuous Features: ['welcome_discount', 'first_premium', 'last_premium', 'first_split', 'last_split', 'last_customer_age', 'last_accident_free_years', 'last_car_value', 'last_age_car', 'last_weight', 'last_product', 'nr_cars', 'fake_alarm', 'last_change_premium_abs', 'last_change_premium_perc', 'n_last_vs_peak', 'last_vs_first_split', 'cum_change_premium_abs', 'cum_change_premium_perc']\n"
     ]
    }
   ],
   "source": [
    "categorical_features = []\n",
    "continuous_features = []\n",
    "binary_features = []\n",
    "\n",
    "# Define a threshold for the maximum number of unique values for a categorical column\n",
    "max_unique_values_for_categorical = 10\n",
    "\n",
    "# Iterate through each column to determine if it's categorical, continuous, or binary\n",
    "for column in df.columns:\n",
    "    unique_values = df[column].nunique()\n",
    "    if unique_values == 2:\n",
    "        # If exactly 2 unique values, treat column as binary\n",
    "        binary_features.append(column)\n",
    "    elif (df[column].dtype == 'object' or unique_values <= max_unique_values_for_categorical) and unique_values > 2:\n",
    "        # If object type or up to the threshold of unique values (and more than 2), treat as categorical\n",
    "        categorical_features.append(column)\n",
    "    else:\n",
    "        # Otherwise, treat as continuous\n",
    "        continuous_features.append(column)\n",
    "\n",
    "print(f'Binary Features: {binary_features}')\n",
    "print(f'Categorical Features: {categorical_features}')\n",
    "print(f'Continuous Features: {continuous_features}')\n",
    "\n",
    "df = pd.get_dummies(df, columns=categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols_to_drop_manual = [\"first_split\", \"first_premium\", \"nr_cars\", \"last_type\", \"last_brand\", 'last_weight', 'n_last_vs_peak', 'last_fuel_type', 'last_trend_nr_coverages', 'last_change_premium_abs', 'last_change_premium_perc', 'max_nr_coverages', 'last_nr_coverages',]\n",
    "cols_to_drop = [\"churn\", \"policy_nr_hashed\", \"last_data_year\", \"first_data_year\", \"control_group\", 'welcome_discount']\n",
    "selected_columns = [col for col in df.columns if not any(col.startswith(prefix) for prefix in cols_to_drop)]\n",
    "\n",
    "X = df[selected_columns]\n",
    "y = df['churn']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_d = {'colsample_bytree': 0.5651430631040584, 'learning_rate': 0.05024033157100756, 'max_depth': 70.0, 'min_child_samples': 33.0, 'min_data_in_leaf': 5.0, 'min_split_gain': 0.0024206836721644767, 'n_estimators': 54.0, 'num_leaves': 185.0, 'reg_alpha': 0.19913197144824663, 'reg_lambda': 0.19906785062440704, 'subsample': 0.9121630873508754, 'subsample_freq': 26.0}\n",
    "\n",
    "best_params_d = {\n",
    "    'max_depth': int(best_d['max_depth']),\n",
    "    'n_estimators': int(best_d['n_estimators']),\n",
    "    'num_leaves': int(best_d['num_leaves']),\n",
    "    'min_child_samples': int(best_d['min_child_samples']),\n",
    "    'colsample_bytree': best_d['colsample_bytree'],\n",
    "    'subsample': best_d['subsample'],\n",
    "    'subsample_freq': int(best_d['subsample_freq']),\n",
    "    'reg_alpha': best_d['reg_alpha'],\n",
    "    'reg_lambda': best_d['reg_lambda'],\n",
    "    'min_split_gain': best_d['min_split_gain'],\n",
    "    'learning_rate': best_d['learning_rate'],\n",
    "    'min_data_in_leaf': int(best_d['min_data_in_leaf']),\n",
    "}\n",
    "\n",
    "ml_d = lgb.LGBMRegressor(\n",
    "    force_row_wise=True,\n",
    "    verbosity=-1,\n",
    "    # is_unbalance=True,\n",
    "    **best_params_d\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_y = {'colsample_bytree': 0.2983935721861137, 'learning_rate': 0.04740706929909022, 'max_depth': 59.0, 'min_child_samples': 18.0, 'min_data_in_leaf': 13.0, 'min_split_gain': 0.3863623673164322, 'n_estimators': 74.0, 'num_leaves': 54.0, 'reg_alpha': 0.1198683978345154, 'reg_lambda': 0.18168767473399486, 'subsample': 0.9841777438197711, 'subsample_freq': 27.0}\n",
    "\n",
    "best_params_y = {\n",
    "    'max_depth': int(best_y['max_depth']),\n",
    "    'n_estimators': int(best_y['n_estimators']),\n",
    "    'num_leaves': int(best_y['num_leaves']),\n",
    "    'min_child_samples': int(best_y['min_child_samples']),\n",
    "    'colsample_bytree': best_y['colsample_bytree'],\n",
    "    'subsample': best_y['subsample'],\n",
    "    'subsample_freq': int(best_y['subsample_freq']),\n",
    "    'reg_alpha': best_y['reg_alpha'],\n",
    "    'reg_lambda': best_y['reg_lambda'],\n",
    "    'min_split_gain': best_y['min_split_gain'],\n",
    "    'learning_rate': best_y['learning_rate'],\n",
    "    'min_data_in_leaf': int(best_y['min_data_in_leaf']),\n",
    "}\n",
    "\n",
    "ml_y = lgb.LGBMClassifier(\n",
    "    objective='binary',\n",
    "    force_row_wise=True,\n",
    "    verbosity=-1,\n",
    "    # is_unbalance=True,\n",
    "    **best_params_y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup DML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/victorperso/Documents/EUR/Aegon Marketing Case/baqm-seminar-16/.conda/lib/python3.8/site-packages/doubleml/double_ml.py:1085: UserWarning: Learner provided for ml_l is probably invalid: LGBMClassifier(colsample_bytree=0.2983935721861137, force_row_wise=True,\n",
      "               learning_rate=0.04740706929909022, max_depth=59,\n",
      "               min_child_samples=18, min_data_in_leaf=13,\n",
      "               min_split_gain=0.3863623673164322, n_estimators=74,\n",
      "               num_leaves=54, objective='binary', reg_alpha=0.1198683978345154,\n",
      "               reg_lambda=0.18168767473399486, subsample=0.9841777438197711,\n",
      "               subsample_freq=27, verbosity=-1) is (probably) no regressor.\n",
      "  warnings.warn(warn_msg_prefix + f'{str(learner)} is (probably) no regressor.')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Aegon Autoverzekering'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m obj_dml_data \u001b[38;5;241m=\u001b[39m dml\u001b[38;5;241m.\u001b[39mDoubleMLData(df, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchurn\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwelcome_discount\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m dml_irm_obj \u001b[38;5;241m=\u001b[39m dml\u001b[38;5;241m.\u001b[39mDoubleMLPLR(obj_dml_data, ml_y, ml_d)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mdml_irm_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/EUR/Aegon Marketing Case/baqm-seminar-16/.conda/lib/python3.8/site-packages/doubleml/double_ml.py:605\u001b[0m, in \u001b[0;36mDoubleML.fit\u001b[0;34m(self, n_jobs_cv, store_predictions, external_predictions, store_models)\u001b[0m\n\u001b[1;32m    602\u001b[0m         ext_prediction_dict[learner] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# ml estimation of nuisance models and computation of score elements\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m score_elements, preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nuisance_est\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__smpls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs_cv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mexternal_predictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mext_prediction_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mreturn_models\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstore_models\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_score_elements(score_elements, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_i_rep, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_i_treat)\n\u001b[1;32m    611\u001b[0m \u001b[38;5;66;03m# calculate rmses and store predictions and targets of the nuisance models\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/EUR/Aegon Marketing Case/baqm-seminar-16/.conda/lib/python3.8/site-packages/doubleml/double_ml_plr.py:173\u001b[0m, in \u001b[0;36mDoubleMLPLR._nuisance_est\u001b[0;34m(self, smpls, n_jobs_cv, external_predictions, return_models)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_nuisance_est\u001b[39m(\u001b[38;5;28mself\u001b[39m, smpls, n_jobs_cv, external_predictions, return_models\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 173\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dml_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dml_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m     x, d \u001b[38;5;241m=\u001b[39m check_X_y(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dml_data\u001b[38;5;241m.\u001b[39md,\n\u001b[1;32m    176\u001b[0m                      force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    177\u001b[0m     m_external \u001b[38;5;241m=\u001b[39m external_predictions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mml_m\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/EUR/Aegon Marketing Case/baqm-seminar-16/.conda/lib/python3.8/site-packages/sklearn/utils/validation.py:1147\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1142\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1144\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1145\u001b[0m     )\n\u001b[0;32m-> 1147\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1163\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1165\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/Documents/EUR/Aegon Marketing Case/baqm-seminar-16/.conda/lib/python3.8/site-packages/sklearn/utils/validation.py:917\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    915\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    916\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 917\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    920\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    921\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/EUR/Aegon Marketing Case/baqm-seminar-16/.conda/lib/python3.8/site-packages/sklearn/utils/_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    378\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 380\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Aegon Autoverzekering'"
     ]
    }
   ],
   "source": [
    "obj_dml_data = dml.DoubleMLData(df, 'churn', 'welcome_discount')\n",
    "\n",
    "dml_irm_obj = dml.DoubleMLPLR(obj_dml_data, ml_y, ml_d)\n",
    "\n",
    "dml_irm_obj.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
