{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import doubleml as dml\n",
    "from doubleml.datasets import make_irm_data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix, roc_auc_score, ConfusionMatrixDisplay, average_precision_score, make_scorer, mean_absolute_error, median_absolute_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from scipy.sparse.linalg import lobpcg\n",
    "# import causalml.inference.meta as cml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/prepped_data.csv\", low_memory=False, index_col=0).drop_duplicates()\n",
    "\n",
    "df = df[df[\"first_data_year\"] >= 2021]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "nulls = [col for col, val in df.isnull().any().to_dict().items() if val == True]\n",
    "print(nulls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\"policy_nr_hashed\", \"last_data_year\", \"first_data_year\", \"first_datapoint_year\", \"last_datapoint_year\"]\n",
    "df = df[[col for col in df.columns.to_list() if (col not in cols_to_drop)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Features: ['churn', 'last_allrisk basis', 'last_allrisk compleet', 'last_allrisk royaal', 'last_wa-extra', 'fake_alarm', 'policyholder_change', 'n_last_vs_peak', 'lpa']\n",
      "Categorical Features: ['count', 'control_group', 'last_brand', 'last_type', 'last_fuel_type', 'last_postcode', 'last_product', 'nr_cars', 'max_nr_coverages', 'last_nr_coverages']\n",
      "Continuous Features: ['welcome_discount', 'first_premium', 'last_premium', 'first_split', 'last_split', 'last_customer_age', 'last_accident_free_years', 'last_car_value', 'last_age_car', 'last_weight', 'accident_years', 'last_change_premium_abs', 'last_change_premium_perc', 'last_vs_first_split', 'cum_change_premium_abs', 'cum_change_premium_perc']\n"
     ]
    }
   ],
   "source": [
    "categorical_features = []\n",
    "continuous_features = []\n",
    "binary_features = []\n",
    "\n",
    "# Define a threshold for the maximum number of unique values for a categorical column\n",
    "max_unique_values_for_categorical = 10\n",
    "\n",
    "# Iterate through each column to determine if it's categorical, continuous, or binary\n",
    "for column in df.columns:\n",
    "    unique_values = df[column].nunique()\n",
    "    if unique_values == 2:\n",
    "        # If exactly 2 unique values, treat column as binary\n",
    "        binary_features.append(column)\n",
    "    elif (df[column].dtype == 'object' or unique_values <= max_unique_values_for_categorical) and unique_values > 2:\n",
    "        # If object type or up to the threshold of unique values (and more than 2), treat as categorical\n",
    "        categorical_features.append(column)\n",
    "    else:\n",
    "        # Otherwise, treat as continuous\n",
    "        continuous_features.append(column)\n",
    "\n",
    "print(f'Binary Features: {binary_features}')\n",
    "print(f'Categorical Features: {categorical_features}')\n",
    "print(f'Continuous Features: {continuous_features}')\n",
    "\n",
    "df = pd.get_dummies(df, columns=categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_d = {'colsample_bytree': 0.5651430631040584, 'learning_rate': 0.05024033157100756, 'max_depth': 70.0, 'min_child_samples': 33.0, 'min_data_in_leaf': 5.0, 'min_split_gain': 0.0024206836721644767, 'n_estimators': 54.0, 'num_leaves': 185.0, 'reg_alpha': 0.19913197144824663, 'reg_lambda': 0.19906785062440704, 'subsample': 0.9121630873508754, 'subsample_freq': 26.0}\n",
    "\n",
    "best_params_d = {\n",
    "    'max_depth': int(best_d['max_depth']),\n",
    "    'n_estimators': int(best_d['n_estimators']),\n",
    "    'num_leaves': int(best_d['num_leaves']),\n",
    "    'min_child_samples': int(best_d['min_child_samples']),\n",
    "    'colsample_bytree': best_d['colsample_bytree'],\n",
    "    'subsample': best_d['subsample'],\n",
    "    'subsample_freq': int(best_d['subsample_freq']),\n",
    "    'reg_alpha': best_d['reg_alpha'],\n",
    "    'reg_lambda': best_d['reg_lambda'],\n",
    "    'min_split_gain': best_d['min_split_gain'],\n",
    "    'learning_rate': best_d['learning_rate'],\n",
    "    'min_data_in_leaf': int(best_d['min_data_in_leaf']),\n",
    "}\n",
    "\n",
    "ml_d = lgb.LGBMClassifier(\n",
    "    objective='binary',\n",
    "    force_row_wise=True,\n",
    "    verbosity=-1,\n",
    "    # is_unbalance=True,\n",
    "    **best_params_d\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_y = {'colsample_bytree': 0.2983935721861137, 'learning_rate': 0.04740706929909022, 'max_depth': 59.0, 'min_child_samples': 18.0, 'min_data_in_leaf': 13.0, 'min_split_gain': 0.3863623673164322, 'n_estimators': 74.0, 'num_leaves': 54.0, 'reg_alpha': 0.1198683978345154, 'reg_lambda': 0.18168767473399486, 'subsample': 0.9841777438197711, 'subsample_freq': 27.0}\n",
    "\n",
    "best_params_y = {\n",
    "    'max_depth': int(best_y['max_depth']),\n",
    "    'n_estimators': int(best_y['n_estimators']),\n",
    "    'num_leaves': int(best_y['num_leaves']),\n",
    "    'min_child_samples': int(best_y['min_child_samples']),\n",
    "    'colsample_bytree': best_y['colsample_bytree'],\n",
    "    'subsample': best_y['subsample'],\n",
    "    'subsample_freq': int(best_y['subsample_freq']),\n",
    "    'reg_alpha': best_y['reg_alpha'],\n",
    "    'reg_lambda': best_y['reg_lambda'],\n",
    "    'min_split_gain': best_y['min_split_gain'],\n",
    "    'learning_rate': best_y['learning_rate'],\n",
    "    'min_data_in_leaf': int(best_y['min_data_in_leaf']),\n",
    "}\n",
    "\n",
    "ml_y = lgb.LGBMClassifier(\n",
    "    objective='binary',\n",
    "    force_row_wise=True,\n",
    "    verbosity=-1,\n",
    "    # is_unbalance=True,\n",
    "    **best_params_y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup DML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_high = df[(df[\"welcome_discount\"] == 1) | (df[\"welcome_discount\"] <= 0.75)]\n",
    "df_med = df[(df[\"welcome_discount\"] == 1) | ((df[\"welcome_discount\"] <= 0.85) & (df[\"welcome_discount\"] > 0.75))]\n",
    "df_low = df[(df[\"welcome_discount\"] == 1) | ((df[\"welcome_discount\"] <= 0.95) & (df[\"welcome_discount\"] > 0.85))]\n",
    "\n",
    "df_high.loc[:, \"welcome_discount\"] = (1 - np.floor(df_high[\"welcome_discount\"])).astype(int)\n",
    "df_med.loc[:, \"welcome_discount\"] = (1 - np.floor(df_med[\"welcome_discount\"])).astype(int)\n",
    "df_low.loc[:, \"welcome_discount\"] = (1 - np.floor(df_low[\"welcome_discount\"])).astype(int)\n",
    "\n",
    "# df_test = df.sample(frac = 0.3, random_state = 0)\n",
    "# df_train = df[~df.index.isin(df_test.index.to_list())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<doubleml.double_ml_irm.DoubleMLIRM at 0x16e15b550>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_dml_data = dml.DoubleMLData(df_high, 'churn', 'welcome_discount')\n",
    "\n",
    "dml_irm_obj = dml.DoubleMLIRM(obj_dml_data, ml_y, ml_d)\n",
    "\n",
    "dml_irm_obj.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>std err</th>\n",
       "      <th>t</th>\n",
       "      <th>P&gt;|t|</th>\n",
       "      <th>2.5 %</th>\n",
       "      <th>97.5 %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>welcome_discount</th>\n",
       "      <td>0.1895</td>\n",
       "      <td>0.005843</td>\n",
       "      <td>32.431382</td>\n",
       "      <td>9.914665e-231</td>\n",
       "      <td>0.178048</td>\n",
       "      <td>0.200953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    coef   std err          t          P>|t|     2.5 %  \\\n",
       "welcome_discount  0.1895  0.005843  32.431382  9.914665e-231  0.178048   \n",
       "\n",
       "                    97.5 %  \n",
       "welcome_discount  0.200953  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dml_irm_obj.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
