{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import gower\n",
    "from sklearn_extra.cluster import KMedoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/prepped_data.csv\", low_memory=False, index_col=0).drop_duplicates()\n",
    "\n",
    "df = df[df[\"first_data_year\"] >= 2021].head(5000)\n",
    "\n",
    "columns_to_keep = [\n",
    "    'first_premium',\n",
    "    'last_premium', 'first_split', 'last_split', 'last_customer_age',\n",
    "    'last_accident_free_years', 'last_car_value', 'last_age_car',\n",
    "    'last_weight', 'last_fuel_type', 'last_postcode', 'last_product',\n",
    "    'last_allrisk basis', 'last_allrisk compleet', 'last_allrisk royaal',\n",
    "    'last_wa-extra', 'last_sales_channel', 'nr_cars', 'fake_alarm',\n",
    "    'policyholder_change', 'max_nr_coverages', 'last_nr_coverages',\n",
    "    'accident_years', 'n_last_vs_peak', 'last_vs_first_split', 'lpa',\n",
    "    'cum_change_premium_abs', 'cum_change_premium_perc', \n",
    "    # 'pc4', 'nr_years',\n",
    "    # 'nr_ppl', 'nr_households', 'household_size', 'nr_homes', 'house_worth',\n",
    "    # 'median_income_household', 'perc_low_income', 'perc_high_income',\n",
    "    # 'ppl_social_help', 'density'\n",
    "]\n",
    "\n",
    "# Filter the DataFrame to keep only the specified columns\n",
    "df = df[columns_to_keep]\n",
    "\n",
    "#columns_clustering = ['last_customer_age', 'last_accident_free_years', 'last_car_value', 'last_age_car', \"last_postcode\", \"last_fuel_type\", \"nr_years\", \"last_premium\", 'last_sales_channel', 'pc4', 'median_income_household', 'density', 'perc_others_ppl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_matrix = gower.gower_matrix(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Medoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmedoids = KMedoids(n_clusters=3, metric='precomputed', random_state=0)\n",
    "kmedoids.fit(dist_matrix)\n",
    "\n",
    "# Output the cluster labels\n",
    "print(\"Cluster labels:\", kmedoids.labels_)\n",
    "\n",
    "df[\"cluster\"] = kmedoids.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    df\n",
    "    .groupby(\"cluster\")\n",
    "    .agg(\n",
    "        # income=pd.NamedAgg(column=\"median_income_household\", aggfunc=\"mean\"),\n",
    "        # perc_low_income=pd.NamedAgg(column=\"perc_low_income\", aggfunc=\"mean\"),\n",
    "        # perc_high_income=pd.NamedAgg(column=\"perc_high_income\", aggfunc=\"mean\"),\n",
    "        # density=pd.NamedAgg(column=\"density\", aggfunc=\"mean\"),\n",
    "        # household_size=pd.NamedAgg(column=\"household_size\", aggfunc=\"mean\"),\n",
    "       # welcome_discount=pd.NamedAgg(column=\"welcome_discount\", aggfunc=\"mean\"),\n",
    "       # churn=pd.NamedAgg(column=\"churn\", aggfunc=\"mean\"),\n",
    "        last_customer_age=pd.NamedAgg(column=\"last_customer_age\", aggfunc=\"mean\"), \n",
    "        count=pd.NamedAgg(column=\"last_customer_age\", aggfunc=\"count\"), \n",
    "        premium = pd.NamedAgg(column='last_premium', aggfunc = 'mean'),\n",
    "        last_accident_free_years =pd.NamedAgg(column=\"last_accident_free_years\", aggfunc=\"mean\"),\n",
    "        last_car_value=pd.NamedAgg(column=\"last_car_value\", aggfunc=\"mean\"),\n",
    "        # perc_others_ppl=pd.NamedAgg(column=\"perc_others_ppl\", aggfunc=\"mean\"),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "\n",
    "\n",
    "# Compute the silhouette score\n",
    "score = silhouette_score(dist_matrix, kmedoids.labels_, metric = 'precomputed')\n",
    "\n",
    "print(\"Silhouette Score:\", score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering\n",
    "import numpy as np\n",
    "beta = 1.0\n",
    "similarity_matrix = np.exp(-beta * dist_matrix ** 2)\n",
    "\n",
    "# Perform Spectral Clustering using the similarity matrix as affinity\n",
    "n_clusters = 3  # Set the number of clusters you wish to find\n",
    "clustering = SpectralClustering(n_clusters=n_clusters, affinity='rbf', n_init=100, assign_labels='discretize')\n",
    "cluster_labels = clustering.fit_predict(dist_matrix)\n",
    "\n",
    "# Output the cluster labels\n",
    "print(\"Cluster labels:\", cluster_labels)\n",
    "df[\"cluster\"] = cluster_labels\n",
    "\n",
    "display(\n",
    "    df\n",
    "    .groupby(\"cluster\")\n",
    "    .agg(\n",
    "        income=pd.NamedAgg(column=\"median_income_household\", aggfunc=\"mean\"),\n",
    "        count=pd.NamedAgg(column=\"median_income_household\", aggfunc=\"count\"),\n",
    "        perc_low_income=pd.NamedAgg(column=\"perc_low_income\", aggfunc=\"mean\"),\n",
    "        perc_high_income=pd.NamedAgg(column=\"perc_high_income\", aggfunc=\"mean\"),\n",
    "        density=pd.NamedAgg(column=\"density\", aggfunc=\"mean\"),\n",
    "        household_size=pd.NamedAgg(column=\"household_size\", aggfunc=\"mean\"),\n",
    "        welcome_discount=pd.NamedAgg(column=\"welcome_discount\", aggfunc=\"mean\"),\n",
    "        churn=pd.NamedAgg(column=\"churn\", aggfunc=\"mean\"),\n",
    "        last_customer_age=pd.NamedAgg(column=\"last_customer_age\", aggfunc=\"mean\"), \n",
    "        last_accident_free_years =pd.NamedAgg(column=\"last_accident_free_years\", aggfunc=\"mean\"),\n",
    "        last_car_value=pd.NamedAgg(column=\"last_car_value\", aggfunc=\"mean\"), \n",
    "        last_premium=pd.NamedAgg(column=\"last_premium\", aggfunc=\"mean\"),\n",
    "        # perc_others_ppl=pd.NamedAgg(column=\"perc_others_ppl\", aggfunc=\"mean\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Compute the silhouette score\n",
    "score = silhouette_score(dist_matrix, cluster_labels, metric = 'precomputed')\n",
    "\n",
    "print(\"Silhouette Score:\", score) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kmodes.kprototypes import KPrototypes\n",
    "\n",
    "\n",
    "X = df.values\n",
    "categorical = [df.columns.get_loc(c) for c in df.select_dtypes(['category','object']).columns]\n",
    "\n",
    "\n",
    "# Initialize the K-Prototypes model\n",
    "kproto = KPrototypes(n_clusters=3, verbose=2, max_iter=20)\n",
    "\n",
    "# Fit the model\n",
    "clusters = kproto.fit_predict(X, categorical=categorical)\n",
    "\n",
    "# Output the cluster for each instance\n",
    "print(\"Cluster assignments:\", clusters)\n",
    "\n",
    "# Cluster centroids\n",
    "print(\"Cluster centroids:\")\n",
    "print(kproto.cluster_centroids_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cluster\"] = clusters\n",
    "\n",
    "\n",
    "display(\n",
    "    df\n",
    "    .groupby(\"cluster\")\n",
    "    .agg(\n",
    "        income=pd.NamedAgg(column=\"median_income_household\", aggfunc=\"mean\"),\n",
    "        count=pd.NamedAgg(column=\"median_income_household\", aggfunc=\"count\"),\n",
    "        perc_low_income=pd.NamedAgg(column=\"perc_low_income\", aggfunc=\"mean\"),\n",
    "        perc_high_income=pd.NamedAgg(column=\"perc_high_income\", aggfunc=\"mean\"),\n",
    "        density=pd.NamedAgg(column=\"density\", aggfunc=\"mean\"),\n",
    "        household_size=pd.NamedAgg(column=\"household_size\", aggfunc=\"mean\"),\n",
    "        welcome_discount=pd.NamedAgg(column=\"welcome_discount\", aggfunc=\"mean\"),\n",
    "        churn=pd.NamedAgg(column=\"churn\", aggfunc=\"mean\"),\n",
    "        last_customer_age=pd.NamedAgg(column=\"last_customer_age\", aggfunc=\"mean\"), \n",
    "        last_accident_free_years =pd.NamedAgg(column=\"last_accident_free_years\", aggfunc=\"mean\"),\n",
    "        last_car_value=pd.NamedAgg(column=\"last_car_value\", aggfunc=\"mean\"), \n",
    "        last_premium=pd.NamedAgg(column=\"last_premium\", aggfunc=\"mean\"),\n",
    "        # perc_others_ppl=pd.NamedAgg(column=\"perc_others_ppl\", aggfunc=\"mean\"),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "categorical_features = []\n",
    "continuous_features = []\n",
    "binary_features = []\n",
    "\n",
    "# List of columns you want to keep\n",
    "columns_to_keep = [\n",
    "     'last_data_year', 'first_datapoint_year',\n",
    "    'last_datapoint_year', 'first_data_year', 'churn', 'first_premium',\n",
    "    'last_premium', 'first_split', 'last_split', 'last_customer_age',\n",
    "    'last_accident_free_years', 'last_car_value', 'last_age_car',\n",
    "    'last_weight', 'last_fuel_type', 'last_postcode', 'last_product',\n",
    "    'last_allrisk basis', 'last_allrisk compleet', 'last_allrisk royaal',\n",
    "    'last_wa-extra', 'last_sales_channel', 'nr_cars', 'fake_alarm',\n",
    "    'policyholder_change', 'max_nr_coverages', 'last_nr_coverages',\n",
    "    'accident_years', 'n_last_vs_peak', 'last_vs_first_split', 'lpa',\n",
    "    'cum_change_premium_abs', 'cum_change_premium_perc', 'pc4', 'nr_years',\n",
    "    'nr_ppl', 'nr_households', 'household_size', 'nr_homes', 'house_worth',\n",
    "    'median_income_household', 'perc_low_income', 'perc_high_income',\n",
    "    'ppl_social_help', 'density'\n",
    "]\n",
    "\n",
    "# Filter the DataFrame to keep only the specified columns\n",
    "df = df[columns_to_keep]\n",
    "\n",
    "\n",
    "# Define a threshold for the maximum number of unique values for a categorical column\n",
    "max_unique_values_for_categorical = 5\n",
    "\n",
    "# Iterate through each column to determine if it's categorical, continuous, or binary\n",
    "for column in df.columns:\n",
    "    unique_values = df[column].nunique()\n",
    "    if unique_values == 2:\n",
    "        # If exactly 2 unique values, treat column as binary\n",
    "        binary_features.append(column)\n",
    "    elif (df[column].dtype == 'object' or unique_values <= max_unique_values_for_categorical) and unique_values > 2:\n",
    "        # If object type or up to the threshold of unique values (and more than 2), treat as categorical\n",
    "        categorical_features.append(column)\n",
    "    else:\n",
    "        # Otherwise, treat as continuous\n",
    "        continuous_features.append(column)\n",
    "\n",
    "categorical_features = [col for col in categorical_features if col != \"nr_years\"]\n",
    "continuous_features = continuous_features + ['nr_years']\n",
    "\n",
    "# print(f'Binary Features: {binary_features}')\n",
    "# print(f'Categorical Features: {categorical_features}')\n",
    "# print(f'Continuous Features: {continuous_features}')\n",
    "\n",
    "df = pd.get_dummies(df, columns=categorical_features, dtype=\"int\")\n",
    "\n",
    "class PFA(object):\n",
    "    def __init__(self, n_features, q=None):\n",
    "        self.q = q\n",
    "        self.n_features = n_features\n",
    "    \n",
    "    def fit(self, X):\n",
    "        if not self.q:\n",
    "            self.q = X.shape[1]\n",
    "    \n",
    "        sc = StandardScaler()\n",
    "        X = sc.fit_transform(X)\n",
    "    \n",
    "        pca = PCA(n_components=self.q).fit(X) # calculation Covmatrix is embeded in PCA\n",
    "        A_q = pca.components_.T\n",
    "    \n",
    "        kmeans = KMeans(n_clusters=self.n_features).fit(A_q)\n",
    "        clusters = kmeans.predict(A_q)\n",
    "        cluster_centers = kmeans.cluster_centers_\n",
    "    \n",
    "        dists = defaultdict(list)\n",
    "        for i, c in enumerate(clusters):\n",
    "            dist = euclidean_distances([A_q[i, :]], [cluster_centers[c, :]])[0][0]\n",
    "            dists[c].append((i, dist))\n",
    "    \n",
    "        self.indices_ = [sorted(f, key=lambda x: x[1])[0][0] for f in dists.values()]\n",
    "        self.features_ = X[:, self.indices_]\n",
    "            \n",
    "# Usage\n",
    "pfa = PFA(n_features=3)\n",
    "pfa.fit(df)\n",
    "# To get the transformed matrix\n",
    "x = pfa.features_\n",
    "print(x)\n",
    "# To get the column indices of the kept features\n",
    "column_indices = pfa.indices_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `df` is your pre-processed DataFrame (after one-hot encoding)\n",
    "\n",
    "# Get the list of original column names (including dummy variables for categorical features)\n",
    "original_columns = list(df.columns)\n",
    "\n",
    "# Map selected indices back to column names\n",
    "selected_feature_names = [original_columns[i] for i in column_indices]\n",
    "\n",
    "print(\"Selected Feature Names:\", selected_feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
