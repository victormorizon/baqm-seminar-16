{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/prepped_data.csv\", index_col = 0, low_memory = False)\n",
    "\n",
    "df = df.drop(columns=['policy_nr_hashed', 'last_data_year', 'first_data_year', 'control_group'])\n",
    "\n",
    "# Filter rows where 'welcome_discount' is 1\n",
    "df = df[df[\"welcome_discount\"] == 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature type identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = []\n",
    "continuous_features = []\n",
    "binary_features = []\n",
    "\n",
    "# Define a threshold for the maximum number of unique values for a categorical column\n",
    "max_unique_values_for_categorical = 10\n",
    "\n",
    "# Iterate through each column to determine if it's categorical, continuous, or binary\n",
    "for column in df.columns:\n",
    "    unique_values = df[column].nunique()\n",
    "    if unique_values == 2:\n",
    "        # If exactly 2 unique values, treat column as binary\n",
    "        binary_features.append(column)\n",
    "    elif (df[column].dtype == 'object' or unique_values <= max_unique_values_for_categorical) and unique_values > 2:\n",
    "        # If object type or up to the threshold of unique values (and more than 2), treat as categorical\n",
    "        categorical_features.append(column)\n",
    "    else:\n",
    "        # Otherwise, treat as continuous\n",
    "        continuous_features.append(column)\n",
    "\n",
    "print(f'Binary Features: {binary_features}')\n",
    "\n",
    "\n",
    "categorical_features.remove('years_since_last_car_change')\n",
    "print(f'Categorical Features: {categorical_features}')\n",
    "print(f'Continuous Features: {continuous_features}')\n",
    "continuous_features.append( 'years_since_last_car_change')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = df['churn']\n",
    "X = df.drop(columns=['churn'])\n",
    "\n",
    "\n",
    "for cat in categorical_features:\n",
    "     X[cat] = X[cat].astype(\"category\")\n",
    "\n",
    "\n",
    "\n",
    "#Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming y_train is your training target variable\n",
    "number_of_positive_instances = sum(y_train == 1)\n",
    "number_of_negative_instances = sum(y_train == 0)\n",
    "\n",
    "# Calculate the scale_pos_weight value\n",
    "scale_pos_weight_value =  number_of_negative_instances /  number_of_positive_instances \n",
    "\n",
    "print(f\"Suggested scale_pos_weight value: {scale_pos_weight_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Hyperparameters & Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, ConfusionMatrixDisplay, make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the search space\n",
    "space = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 50, 200, 1),\n",
    "    'max_depth': hp.quniform('max_depth', 3, 10, 1),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
    "    'subsample': hp.uniform('subsample', 0.6, 1.0),\n",
    "    'gamma': hp.uniform('gamma', 0, 0.5),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1.0),\n",
    "    'min_child_weight': hp.quniform('min_child_weight', 8, 20, 1),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0, 1),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0, 1)\n",
    "}\n",
    "\n",
    "\n",
    "        \n",
    "def objective(space):\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=int(space['n_estimators']),\n",
    "        max_depth=int(space['max_depth']),\n",
    "        learning_rate=space['learning_rate'],\n",
    "        subsample=space['subsample'],\n",
    "        gamma=space['gamma'],\n",
    "        colsample_bytree=space['colsample_bytree'],\n",
    "        min_child_weight = space['min_child_weight'],\n",
    "        reg_alpha=space['reg_alpha'],\n",
    "        # scale_pos_weight=scale_pos_weight_value,\n",
    "        reg_lambda=space['reg_lambda'],\n",
    "        objective='binary:logistic',\n",
    "        tree_method='hist',\n",
    "        enable_categorical=True \n",
    "    )\n",
    "    \n",
    "    # Using cross-validation for evaluation\n",
    "    score = cross_val_score(model, X_train, y_train, cv=5, scoring = 'neg_brier_score' ).mean()\n",
    "\n",
    "    # We aim to maximize f1, hence we return its negative value\n",
    "    return {'loss': - score, 'status': STATUS_OK}\n",
    "\n",
    "# Run the algorithm\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=50, trials=trials)\n",
    "\n",
    "print(\"Best parameters:\", best)\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation metrics & Optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Best parameters brier: {'colsample_bytree': 0.6214603166799485, 'gamma': 0.09327251345789303, 'learning_rate': 0.19861493186183998, 'max_depth': 10.0, 'min_child_weight': 9.0, 'n_estimators': 176.0, 'reg_alpha': 0.18239980169633493, 'reg_lambda': 0.7207028599747125, 'subsample': 0.8797605417401115}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, ConfusionMatrixDisplay, average_precision_score, median_absolute_error, mean_absolute_error\n",
    "\n",
    "# Use the best parameters\n",
    "model = XGBClassifier(\n",
    "    n_estimators=int(best['n_estimators']),\n",
    "    max_depth=int(best['max_depth']),\n",
    "    learning_rate=best['learning_rate'],\n",
    "    subsample=best['subsample'],\n",
    "    gamma=best['gamma'],\n",
    "    colsample_bytree=best['colsample_bytree'],\n",
    "    min_child_weight = best['min_child_weight'],\n",
    "    # scale_pos_weight=scale_pos_weight_value,\n",
    "    reg_alpha=best['reg_alpha'],\n",
    "    reg_lambda=best['reg_lambda'],\n",
    "    objective='binary:logistic',\n",
    "    tree_method='hist',\n",
    "    enable_categorical = True\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "# preds = model.predict_proba(X_test)\n",
    "\n",
    "threshold = 0.5\n",
    "probabilities = model.predict_proba(X_test)[:, 1]\n",
    "preds = np.abs(np.ceil(np.array(probabilities) - threshold)).astype(\"int\")\n",
    "\n",
    "def mae_prob(y_true, y_pred_probs):\n",
    "    return mean_absolute_error(y_true, y_pred_probs)\n",
    "\n",
    "def medae_prob(y_true, y_pred_probs):\n",
    "    return median_absolute_error(y_true, y_pred_probs)\n",
    "\n",
    "mae_prob_scorer = make_scorer(mae_prob, needs_proba=True)\n",
    "medae_prob_scorer = make_scorer(medae_prob, needs_proba=True)\n",
    "\n",
    "logloss_score = cross_val_score(model, X, y, scoring= 'neg_log_loss')\n",
    "brier_score = cross_val_score(model, X, y, cv = 5, scoring = 'neg_brier_score')\n",
    "scores_mae = cross_val_score(model, X, y, cv=5, scoring=mae_prob_scorer)\n",
    "scores_medae = cross_val_score(model, X, y, cv=5, scoring=medae_prob_scorer)\n",
    "\n",
    "\n",
    "# scores_custom = cross_val_score(model, X, y, cv=5, scoring=custom_cost_score)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, preds)\n",
    "\n",
    "\n",
    "\n",
    "print('CV Average logloss: {0:0.4f}'.format(np.mean(logloss_score)))\n",
    "print('CV mean_absolute_error: {0:0.4f}'.format(np.mean(scores_mae)))\n",
    "print('CV Average  brier score: {0:0.4f}'.format(np.mean(brier_score)))\n",
    "print('CV median_absolute_error: {0:0.4f}'.format(np.mean(scores_medae)))\n",
    "\n",
    "\n",
    "# print('CV Average Custom score: {0:0.4f}'.format(np.mean(scores_custom)))\n",
    "\n",
    "# Plot confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as pyplot\n",
    "\n",
    "# Now you can use plt to create plots\n",
    "\n",
    "print(model.feature_importances_)\n",
    "# plot\n",
    "pyplot.bar(range(len(model.feature_importances_)), model.feature_importances_)\n",
    "pyplot.xticks(range(len(model.feature_importances_)), X.columns, rotation='vertical')\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
