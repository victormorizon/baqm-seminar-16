{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = pd.read_csv(\"./data/20240117_churn_data.csv\", low_memory=False).drop_duplicates()\n",
    "pc4_df = pd.read_csv(\"./data/pc4_data.csv\", low_memory=False, delimiter=\";\", decimal=\",\").drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tryconvert(value, default, *types):\n",
    "    for t in types:\n",
    "        try:\n",
    "            return t(value)\n",
    "        except (ValueError, TypeError, IndexError):\n",
    "            continue\n",
    "    return default\n",
    "\n",
    "def count_decreases(group):\n",
    "    # Shift the 'Value' column down to compare with the next row\n",
    "    prev_values = group['policy_nr_hashed'].shift(1)\n",
    "    # Check if the current value is greater than the next value\n",
    "    decreases = group['policy_nr_hashed'] > prev_values\n",
    "    # Sum the True values (which represent decreases)\n",
    "    return decreases.sum()\n",
    "\n",
    "def last_non_zero(series):\n",
    "    non_zero_values = series.replace(0, np.NaN).dropna()\n",
    "    if not non_zero_values.empty:\n",
    "        return non_zero_values.iloc[-1]\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def second_to_last(series):\n",
    "    return series.iloc[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep customers that joined after welcome discount was introduced\n",
    "input_df = input_df.sort_values(\"year_initiation_policy_version\")\n",
    "\n",
    "# Only keep customers that have at least two data-points\n",
    "input_df[\"number_datapoints\"] = input_df.groupby('policy_nr_hashed')[['policy_nr_hashed']].transform('count')\n",
    "input_df = input_df[input_df[\"number_datapoints\"] > 1]\n",
    "\n",
    "# We need to filter out all the customers that churned \n",
    "input_df['non_relevant_churn'] = input_df.groupby('policy_nr_hashed')[['d_churn_between_prolongations', 'd_churn_cancellation']].transform('sum').sum(axis=1)\n",
    "input_df = input_df[input_df['non_relevant_churn'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Relevant Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A column that says whether a customer got a discount or not\n",
    "input_df[\"has_discount\"] = (input_df.groupby('policy_nr_hashed')[['welcome_discount']].transform('min') < 1)\n",
    "\n",
    "# Create a dict of all the premium data\n",
    "input_df['premium_data'] = input_df.apply(lambda row: {'year': int(row['year_initiation_policy_version']), 'main': np.round(row['premium_main_coverages'], 0), 'supp': np.round(row['premium_supplementary_coverages'], 0), 'total': np.round(row['total_premium'], 0)}, axis=1)\n",
    "\n",
    "# How much of the premium is main coverage\n",
    "input_df['main_coverage_portion'] = input_df['premium_main_coverages'] / input_df['total_premium']\n",
    "\n",
    "# Aggregate all car-data into a single column\n",
    "input_df['car_data'] = input_df[\"brand\"] + input_df[\"type\"] + input_df[\"weight\"].astype(str) + input_df[\"fuel_type\"]\n",
    "input_df[\"lagged_car_data\"] = input_df.groupby('policy_nr_hashed')['car_data'].shift(1)\n",
    "input_df[\"car_change\"] = ((input_df[\"lagged_car_data\"] != input_df[\"car_data\"]) & ~input_df['lagged_car_data'].isnull())\n",
    "input_df[\"year_car_change\"] = input_df[\"car_change\"].astype(\"int\") * input_df[\"year_initiation_policy_version\"]\n",
    "\n",
    "# Concatenate all mutations\n",
    "input_df[\"all_mutations\"] = input_df[[col for col in input_df.columns if ((\"mutation\" in col) and (len(col) < 12))]].astype(\"str\").sum(1).str.replace('nan', '')\n",
    "\n",
    "# Tag when a policy has changed holder\n",
    "input_df[\"policyholder_change\"] = input_df[\"all_mutations\"].str.contains(\"replacePolicyholder\")\n",
    "input_df[\"fake_alarm\"] = input_df[\"all_mutations\"].str.contains(\"restoreCancellation\")\n",
    "\n",
    "# Compute total lagged coverage\n",
    "input_df['n_coverages_trend'] = input_df[\"n_coverages\"] - input_df.groupby('policy_nr_hashed')['n_coverages'].shift(1)\n",
    "\n",
    "# Calculate number of accdent years\n",
    "input_df[\"accident_years\"] = ((input_df.groupby('policy_nr_hashed')['accident_free_years'].shift(1) > input_df['accident_free_years']).astype(\"int\") * (input_df.groupby('policy_nr_hashed')['accident_free_years'].shift(1) - input_df['accident_free_years'])).fillna(0).replace(-0.0, 0)\n",
    "\n",
    "# Create lagged premium difference (abs and perc)\n",
    "input_df[\"lagged_total_premium\"] = input_df.groupby('policy_nr_hashed')['total_premium'].shift(1)\n",
    "input_df[\"abs_diff_total_premium\"] = input_df[\"total_premium\"] - input_df[\"lagged_total_premium\"]\n",
    "input_df[\"perc_diff_total_premium\"] = input_df[\"abs_diff_total_premium\"] / input_df[\"lagged_total_premium\"]\n",
    "\n",
    "# display(input_df[input_df[\"policy_nr_hashed\"] == \"lrzJmX0\"][[\"year_initiation_policy_version\", \"car_data\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_data_columns = ['customer_age', 'accident_free_years', 'car_value', 'age_car', 'brand', 'type', 'weight', 'fuel_type', 'postcode', 'product', 'allrisk basis', 'allrisk compleet', 'allrisk royaal', 'wa-extra', 'sales_channel']\n",
    "customer_data_agg = {f'last_{col}': pd.NamedAgg(column=col, aggfunc=second_to_last) for col in customer_data_columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = (\n",
    "    input_df\n",
    "    .sort_values(\"year_initiation_policy_version\")\n",
    "    .groupby(\"policy_nr_hashed\")\n",
    "    .agg(\n",
    "        welcome_discount=pd.NamedAgg(column=\"welcome_discount\", aggfunc=\"min\"),\n",
    "        count=pd.NamedAgg(column=\"welcome_discount\", aggfunc=\"count\"),\n",
    "        last_data_year=pd.NamedAgg(column=\"year_initiation_policy_version\", aggfunc=second_to_last),\n",
    "        first_datapoint_year=pd.NamedAgg(column=\"year_initiation_policy_version\", aggfunc=\"first\"),\n",
    "        last_datapoint_year=pd.NamedAgg(column=\"year_initiation_policy_version\", aggfunc=\"last\"),\n",
    "        first_data_year=pd.NamedAgg(column=\"year_initiation_policy\", aggfunc=\"first\"),\n",
    "        churn=pd.NamedAgg(column=\"d_churn_around_prolongation\", aggfunc=\"max\"),\n",
    "        control_group=pd.NamedAgg(column=\"welcome_discount_control_group\", aggfunc='first'),\n",
    "        first_premium=pd.NamedAgg(column=\"total_premium\", aggfunc='first'),\n",
    "        last_premium=pd.NamedAgg(column=\"total_premium\", aggfunc=second_to_last),\n",
    "        first_split=pd.NamedAgg(column=\"main_coverage_portion\", aggfunc='first'),\n",
    "        last_split=pd.NamedAgg(column=\"main_coverage_portion\", aggfunc=second_to_last),\n",
    "        **customer_data_agg,\n",
    "        nr_cars=pd.NamedAgg(column=\"car_data\", aggfunc=lambda x:len(set(x.to_list()[:-1]))),\n",
    "        fake_alarm=pd.NamedAgg(column=\"fake_alarm\", aggfunc=lambda x:np.sum(x.to_list()[:-1])),\n",
    "        policyholder_change=pd.NamedAgg(column=\"policyholder_change\", aggfunc=lambda x:np.sum(x.to_list()[:-1])),\n",
    "        max_nr_coverages=pd.NamedAgg(column=\"n_coverages\", aggfunc=lambda x:np.max(x.to_list()[:-1])),\n",
    "        last_nr_coverages=pd.NamedAgg(column=\"n_coverages\", aggfunc=second_to_last),\n",
    "        accident_years=pd.NamedAgg(column=\"accident_years\", aggfunc=lambda x:np.sum(x.to_list()[:-1])),\n",
    "        # last_year_car_change=pd.NamedAgg(column=\"year_car_change\", aggfunc=last_non_zero),\n",
    "        # last_change_premium_abs=pd.NamedAgg(column=\"abs_diff_total_premium\", aggfunc=second_to_last),\n",
    "        # last_change_premium_perc=pd.NamedAgg(column=\"perc_diff_total_premium\", aggfunc=second_to_last),\n",
    "    )\n",
    "    # .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s0/7_fb0swx3w172221bbtj_36m0000gp/T/ipykernel_9806/2526077894.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['pc4'] = final_df['last_postcode'].astype(int)\n",
      "/var/folders/s0/7_fb0swx3w172221bbtj_36m0000gp/T/ipykernel_9806/2526077894.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['last_postcode'] = final_df['last_postcode'].astype(str).str[0]\n",
      "/var/folders/s0/7_fb0swx3w172221bbtj_36m0000gp/T/ipykernel_9806/2526077894.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['nr_years'] = final_df[\"last_data_year\"] - final_df[\"first_data_year\"]\n",
      "/var/folders/s0/7_fb0swx3w172221bbtj_36m0000gp/T/ipykernel_9806/2526077894.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df[\"welcome_discount\"] = 1 - final_df[\"welcome_discount\"]\n"
     ]
    }
   ],
   "source": [
    "# final_df[\"years_since_last_car_change\"] = (final_df[\"last_data_year\"] - final_df[\"last_year_car_change\"]).astype(\"int\").apply(lambda x: x if x <= 10 else 1e6)\n",
    "final_df[\"n_last_vs_peak\"] = final_df[\"last_nr_coverages\"] - final_df[\"max_nr_coverages\"]\n",
    "final_df[\"last_vs_first_split\"] = final_df[\"last_split\"] - final_df[\"first_split\"]\n",
    "final_df[\"lpa\"] = (~final_df[\"control_group\"].str.contains(\"no LPA\")).astype(\"int\")\n",
    "final_df[\"cum_change_premium_abs\"] = final_df[\"last_premium\"] - final_df[\"first_premium\"]\n",
    "final_df[\"cum_change_premium_perc\"] = final_df[\"cum_change_premium_abs\"] / final_df[\"first_premium\"]\n",
    "\n",
    "final_df['last_postcode'] = pd.to_numeric(final_df['last_postcode'], errors='coerce')\n",
    "final_df = final_df.dropna(subset=['last_postcode'])\n",
    "final_df['pc4'] = final_df['last_postcode'].astype(int)\n",
    "\n",
    "final_df['last_postcode'] = final_df['last_postcode'].astype(str).str[0]\n",
    "final_df['nr_years'] = final_df[\"last_data_year\"] - final_df[\"first_data_year\"]\n",
    "final_df[\"welcome_discount\"] = 1 - final_df[\"welcome_discount\"]\n",
    "\n",
    "final_df = final_df[(final_df[\"last_datapoint_year\"] - final_df[\"first_datapoint_year\"]) == (final_df[\"count\"] - 1)]\n",
    "final_df = final_df[final_df[\"last_premium\"] > 0]\n",
    "\n",
    "# display(final_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Postal Code Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc4_df = pc4_df[~(pc4_df.lt(0)).any(axis=1)]\n",
    "\n",
    "final_final_df = final_df.merge(pc4_df, on='pc4', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_final_df.to_csv(\"./data/prepped_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
