{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = pd.read_csv(\"./data/20240117_churn_data.csv\", low_memory=False).drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tryconvert(value, default, *types):\n",
    "    for t in types:\n",
    "        try:\n",
    "            return t(value)\n",
    "        except (ValueError, TypeError, IndexError):\n",
    "            continue\n",
    "    return default\n",
    "\n",
    "def count_decreases(group):\n",
    "    # Shift the 'Value' column down to compare with the next row\n",
    "    prev_values = group['policy_nr_hashed'].shift(1)\n",
    "    # Check if the current value is greater than the next value\n",
    "    decreases = group['policy_nr_hashed'] > prev_values\n",
    "    # Sum the True values (which represent decreases)\n",
    "    return decreases.sum()\n",
    "\n",
    "def last_non_zero(series):\n",
    "    non_zero_values = series.replace(0, np.NaN).dropna()\n",
    "    if not non_zero_values.empty:\n",
    "        return non_zero_values.iloc[-1]\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep customers that joined after welcome discount was introduced\n",
    "input_df = input_df[input_df[\"year_initiation_policy\"] >= 2021].sort_values(\"year_initiation_policy_version\")\n",
    "\n",
    "# We need to filter out all the customers that churned \n",
    "input_df['non_relevant_churn'] = input_df.groupby('policy_nr_hashed')[['d_churn_between_prolongations', 'd_churn_cancellation']].transform('sum').sum(axis=1)\n",
    "input_df = input_df[input_df['non_relevant_churn'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Relevant Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A variable that says how long it took for a customer to churn (0 means he didn't churn yet, 5 means he churned 5 years after joining)\n",
    "input_df[\"years_to_churn\"] = input_df[\"years_since_policy_started\"] * input_df[\"d_churn_around_prolongation\"]\n",
    "\n",
    "# A column that says whether a customer got a discount or not\n",
    "input_df[\"has_discount\"] = (input_df.groupby('policy_nr_hashed')[['welcome_discount']].transform('min') < 1)\n",
    "\n",
    "# Create a dict of all the premium data\n",
    "input_df['premium_data'] = input_df.apply(lambda row: {'year': int(row['year_initiation_policy_version']), 'main': np.round(row['premium_main_coverages'], 0), 'supp': np.round(row['premium_supplementary_coverages'], 0), 'total': np.round(row['total_premium'], 0)}, axis=1)\n",
    "\n",
    "# How much of the premium is main coverage\n",
    "input_df['main_coverage_portion'] = input_df['premium_main_coverages'] / input_df['total_premium']\n",
    "\n",
    "# Aggregate all car-data into a single column\n",
    "input_df['car_data'] = input_df[\"brand\"] + input_df[\"type\"] + input_df[\"weight\"].astype(str) + input_df[\"fuel_type\"]\n",
    "input_df[\"lagged_car_data\"] = input_df.groupby('policy_nr_hashed')['car_data'].shift(1)\n",
    "input_df[\"car_change\"] = ((input_df[\"lagged_car_data\"] != input_df[\"car_data\"]) & ~input_df['lagged_car_data'].isnull())\n",
    "input_df[\"year_car_change\"] = input_df[\"car_change\"].astype(\"int\") * input_df[\"year_initiation_policy_version\"]\n",
    "\n",
    "# Concatenate all mutations\n",
    "input_df[\"all_mutations\"] = input_df[[col for col in input_df.columns if ((\"mutation\" in col) and (len(col) < 12))]].astype(\"str\").sum(1).str.replace('nan', '')\n",
    "\n",
    "# Tag when a policy has changed holder\n",
    "input_df[\"policyholder_change\"] = input_df[\"all_mutations\"].str.contains(\"replacePolicyholder\")\n",
    "input_df[\"fake_alarm\"] = input_df[\"all_mutations\"].str.contains(\"restoreCancellation\")\n",
    "\n",
    "# Compute total lagged coverage\n",
    "input_df['n_coverages_trend'] = input_df[\"n_coverages\"] - input_df.groupby('policy_nr_hashed')['n_coverages'].shift(1)\n",
    "\n",
    "# Calculate number of accdent years\n",
    "input_df[\"accident_years\"] = ((input_df.groupby('policy_nr_hashed')['accident_free_years'].shift(1) > input_df['accident_free_years']).astype(\"int\") * (input_df.groupby('policy_nr_hashed')['accident_free_years'].shift(1) - input_df['accident_free_years'])).fillna(0).replace(-0.0, 0)\n",
    "\n",
    "# Create lagged premium difference (abs and perc)\n",
    "input_df[\"lagged_total_premium\"] = input_df.groupby('policy_nr_hashed')['total_premium'].shift(1)\n",
    "input_df[\"abs_diff_total_premium\"] = input_df[\"total_premium\"] - input_df[\"lagged_total_premium\"]\n",
    "input_df[\"perc_diff_total_premium\"] = input_df[\"abs_diff_total_premium\"] / input_df[\"lagged_total_premium\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_data_columns = ['customer_age', 'accident_free_years', 'car_value', 'age_car', 'brand', 'type', 'weight', 'fuel_type', 'postcode', 'product', 'allrisk basis', 'allrisk compleet', 'allrisk royaal', 'wa-extra', 'wettelijke aansprakelijkheid']\n",
    "customer_data_agg = {f'last_{col}': pd.NamedAgg(column=col, aggfunc='last') for col in customer_data_columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = (\n",
    "    input_df\n",
    "    .sort_values(\"year_initiation_policy_version\")\n",
    "    .groupby(\"policy_nr_hashed\")\n",
    "    .agg(\n",
    "        welcome_discount=pd.NamedAgg(column=\"welcome_discount\", aggfunc=\"min\"),\n",
    "        last_data_year=pd.NamedAgg(column=\"year_initiation_policy_version\", aggfunc=\"last\"),\n",
    "        years_to_churn=pd.NamedAgg(column=\"years_to_churn\", aggfunc=\"max\"),\n",
    "        control_group=pd.NamedAgg(column=\"welcome_discount_control_group\", aggfunc=\"first\"),\n",
    "        premiums=pd.NamedAgg(column=\"premium_data\", aggfunc=lambda x: x.to_list()),\n",
    "        first_premium=pd.NamedAgg(column=\"total_premium\", aggfunc='first'),\n",
    "        last_premium=pd.NamedAgg(column=\"total_premium\", aggfunc='last'),\n",
    "        first_split=pd.NamedAgg(column=\"main_coverage_portion\", aggfunc='first'),\n",
    "        last_split=pd.NamedAgg(column=\"main_coverage_portion\", aggfunc='last'),\n",
    "        **customer_data_agg,\n",
    "        nr_cars=pd.NamedAgg(column=\"car_data\", aggfunc=lambda x:np.size(set(x.to_list()))),\n",
    "        fake_alarm=pd.NamedAgg(column=\"fake_alarm\", aggfunc='sum'),\n",
    "        policyholder_change=pd.NamedAgg(column=\"policyholder_change\", aggfunc='sum'),\n",
    "        max_nr_coverages=pd.NamedAgg(column=\"n_coverages\", aggfunc='max'),\n",
    "        last_nr_coverages=pd.NamedAgg(column=\"n_coverages\", aggfunc='last'),\n",
    "        last_trend_nr_coverages=pd.NamedAgg(column=\"n_coverages_trend\", aggfunc=\"last\"),\n",
    "        accident_years=pd.NamedAgg(column=\"accident_years\", aggfunc=\"sum\"),\n",
    "        last_year_car_change=pd.NamedAgg(column=\"year_car_change\", aggfunc=last_non_zero),\n",
    "        last_change_premium_abs=pd.NamedAgg(column=\"abs_diff_total_premium\", aggfunc=\"last\"),\n",
    "        last_change_premium_perc=pd.NamedAgg(column=\"perc_diff_total_premium\", aggfunc=\"last\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[\"years_since_last_car_change\"] = (final_df[\"last_data_year\"] - final_df[\"last_year_car_change\"]).astype(\"int\").apply(lambda x: x if x <= 10 else np.NaN)\n",
    "final_df[\"n_last_vs_peak\"] = final_df[\"last_nr_coverages\"] - final_df[\"max_nr_coverages\"]\n",
    "final_df[\"last_vs_first_split\"] = final_df[\"last_split\"] - final_df[\"first_split\"]\n",
    "final_df[\"lpa\"] = (~final_df[\"control_group\"].str.contains(\"no LPA\")).astype(\"int\")\n",
    "final_df[\"cum_change_premium_abs\"] = final_df[\"last_premium\"] - final_df[\"first_premium\"]\n",
    "final_df[\"cum_change_premium_perc\"] = final_df[\"cum_change_premium_abs\"] / final_df[\"first_premium\"]\n",
    "\n",
    "# final_df.to_csv(\"./data/prepped_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
